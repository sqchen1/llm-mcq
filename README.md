# LLM Multiple-Choice Questions

This project uses **OpenAI APIs** through **LangChain** package to evaluate the performance of large language models (LLMs) on multiple-choice business analysis questions. 
The python script reads questions from an Excel file, calls 3 models in parallel, and records their answers in a structured Excel file as the output.

## How It Works

1. **Input:**  
   The file `test_qa.xlsx` contains 5 llm-generated multiple-choice sample questions (columns:  `task_id`, `Question` and `FormatRequirement`).

2. **Processing:**  
   The python script `evaluation.py` uses LangChain to call three models in parallel, they are:
   - GPT-4.1  
   - GPT-3.5-turbo  
   - GPT-4o-mini  

3. **Output:**  
   Results are saved to `output_with_answers.xlsx`.

Note: The questions in `test_qa.xlsx` were generated by GPT-5. The text file `prompt_for_question_generation.md` records the exact prompt I used to generate these questions.


